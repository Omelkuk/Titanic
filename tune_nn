import optuna
import pandas as pd
import torch
import yaml
import numpy as np
from omegaconf import OmegaConf
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import VotingClassifier, StackingClassifier


from factory import TitanicNN, create_data_loader, train_nn
from main import get_model, clean_data, predict_probs, get_Stacking_Ensemble, get_Voting_Ensemble

def objective(trial, X, y, cfg):
    active_name = cfg.active_model
    m_cfg = cfg.models.get(active_name, {})
    seed = cfg.data.seed
    params = {}

   
    if active_name in ["lr", "lasso", "ridge", "elasticnet"]:
        params['C'] = trial.suggest_float("C", 1e-4, 10.0, log=True)
        if active_name == "ridge":
            params['alpha'] = trial.suggest_float("alpha", 0.01, 20.0)
        if active_name == "elasticnet":
            params['l1_ratio'] = trial.suggest_float("l1_ratio", 0, 1)

  
    elif active_name == "knn":
        params['n_neighbors'] = trial.suggest_int("n_neighbors", 2, 30)
        params['weights'] = trial.suggest_categorical("weights", ["uniform", "distance"])
        params['metric'] = trial.suggest_categorical("metric", ["euclidean", "manhattan"])


    elif active_name == "dt":
        params['max_depth'] = trial.suggest_int("max_depth", 2, 25)
        params['criterion'] = trial.suggest_categorical("criterion", ["gini", "entropy"])
        params['min_samples_split'] = trial.suggest_int("min_samples_split", 2, 20)

  
    elif active_name == "rf":
        params['n_estimators'] = trial.suggest_int("n_estimators", 50, 800)
        params['max_depth'] = trial.suggest_int("max_depth", 2, 30)
        params['min_samples_leaf'] = trial.suggest_int("min_samples_leaf", 1, 10)

    
    elif active_name in ["xgb", "lgb"]:
        params['n_estimators'] = trial.suggest_int("n_estimators", 100, 1000)
        params['learning_rate'] = trial.suggest_float("learning_rate", 1e-3, 0.2, log=True)
        params['max_depth'] = trial.suggest_int("max_depth", 3, 15)
        if active_name == "lgb":
            params['num_leaves'] = trial.suggest_int("num_leaves", 20, 150)
        if active_name == "xgb":
            params['gamma'] = trial.suggest_float("gamma", 1e-8, 1.0, log=True)

   
    elif active_name == "nn":
        lr = trial.suggest_float("lr", *m_cfg.tuning.lr, log=True)
     
        model = get_model(m_cfg, seed, input_dim=X.shape[1], trial=trial)
        
        X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=seed)
        train_loader = create_data_loader(X_tr, y_tr, batch_size=m_cfg.batch_size)
        
        model = train_nn(model, train_loader, epochs=50, lr=lr)
        probs = predict_probs(model, X_val)
        return roc_auc_score(y_val, probs)

   
    elif active_name == "voting":
        w_lgb = trial.suggest_float("w_lgb", 0.1, 1.0)
        w_xgb = trial.suggest_float("w_xgb", 0.1, 1.0)
        w_rf  = trial.suggest_float("w_rf",  0.1, 1.0)
        model = get_Voting_Ensemble(cfg, seed)
        model.weights = [w_lgb, w_xgb, w_rf]

    elif active_name == "stacking":
        meta_C = trial.suggest_float("meta_C", 0.001, 10.0, log=True)
        model = get_Stacking_Ensemble(cfg, seed)
        model.final_estimator.C = meta_C

  
    if active_name not in ["nn", "voting", "stacking"]:
        temp_m_cfg = OmegaConf.merge(m_cfg, params)
        model = get_model(temp_m_cfg, seed)
    
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)
    score = cross_val_score(model, X, y, cv=skf, scoring='roc_auc', n_jobs=-1).mean()
    return score

def running_tuning(cfg_path="config/config.yaml"):
    cfg = OmegaConf.load(cfg_path)
    active_name = cfg.active_model
    
    print(f" Запуск тюнинга: {active_name.upper()}")
    
    df = pd.read_csv(cfg.data.raw)
    df_cleaned = clean_data(df)
    X = df_cleaned.drop("Survived", axis=1, errors='ignore')
    y = df_cleaned["Survived"]
    
    scaler = StandardScaler().set_output(transform="pandas")
    X_scaled = scaler.fit_transform(X)

    study = optuna.create_study(direction="maximize")
    study.optimize(lambda trial: objective(trial, X_scaled, y, cfg), n_trials=cfg.tuner.n_trials)

    print(f"\n Лучший ROC-AUC для {active_name}: {study.best_value:.4f}")
    
    
    with open(cfg_path, 'r', encoding='utf-8') as f:
        full_config = yaml.safe_load(f)

    
    if active_name == "nn":
        target = full_config['models']['nn']['best_params']
    else:
        if active_name not in full_config['models']:
            full_config['models'][active_name] = {'type': active_name}
        target = full_config['models'][active_name]

    print(" Записываю параметры в конфиг:")
    for key, value in study.best_params.items():
        target[key] = value
        print(f"  {key} -> {value}")

    with open(cfg_path, 'w', encoding='utf-8') as f:
        yaml.dump(full_config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
    
    print(f" Готово! Модель {active_name} настроена.")

if __name__ == "__main__":
    running_tuning()